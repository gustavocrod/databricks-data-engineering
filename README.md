# üöß O projeto
Esse √© um projeto de data engineering utilizando arquitetura medallion com databricks. Aqui focamos em aplicar conceitos de Delta Lake House, e aquisi√ß√£o, limpeza e modelagem de dados.

Ap√≥s ingerirmos os dados do Kaggle, iremos fazer transforma√ß√µes e responder algumas perguntas de neg√≥cio, como:
- 1: Quantas vendas ocorrem por estado?
- 2: Qual loja/cidade captou o maior valor em vendas?
  - 2.1: Quanto desse valor veio por valor do produto?
  - 2.2: Quando desse valor foi por frete?
- 3: Qual a rela√ß√£o entre o dia de compra e o atraso na entrega?
- 4: Qual a rela√ß√£o entre o tempo da compra at√© o envio com o tempo total at√© a entrega?
- 5: Quais s√£o os maiores compradores? (rec√™ncia, frequ√™ncia e valor gasto)

Essas e outras tantas perguntas podem ser respondidas com os dados que trataremos.

Juntem-se a mim, enquanto temos um overview do projeto.

----
# üóÉÔ∏è Brazilian ecommerce olist

Este √© um conjunto de dados p√∫blicos de com√©rcio eletr√¥nico brasileiro das compras feitas na loja Olist. O conjunto de dados cont√©m informa√ß√µes de 100 mil pedidos de 2016 a 2018 feitos em v√°rios marketplaces no Brasil. Suas caracter√≠sticas permitem visualizar um pedido em v√°rias dimens√µes: desde o status do pedido, pre√ßo, pagamento e desempenho de frete at√© a localiza√ß√£o do cliente, atributos do produto e, finalmente, avalia√ß√µes escritas pelos clientes. Tamb√©m disponibilizamos um conjunto de dados de geolocaliza√ß√£o que relaciona os c√≥digos postais brasileiros √†s coordenadas lat/long.

Estes s√£o dados comerciais reais, foram anonimizados, e as refer√™ncias √†s empresas e parceiros no texto de revis√£o foram substitu√≠das pelos nomes das grandes casas de Game of Thrones.

## 1 - Ingest√£o de dados (staging)
O arquivo .ipynb respons√°vel pela ingest√£o pode ser visto [aqui](https://github.com/gustavocrod/databricks-data-engineering-olist/blob/main/0%20-%20data_ingestion%20(staging).ipynb)

O dataset escolhido foi o [Brazilian E-Commerce Public Dataset by Olist](https://www.kaggle.com/datasets/olistbr/brazilian-ecommerces)

Como √© um dataset est√°tico (ou quase 100%), n√£o faz sentido adicionar upsert e tampouco streaming.

Mas aqui poder√≠amos utilizar do AutoLoader, ou at√© mesmo de alguma ferramenta com CDC, como airbyte.

Nossa staging n√£o precisaria existir (apenas caso fossem dados vindos por airbyte, por exemplo). Mas criamos para exemplificar, pois irei salvar a staging em parquet. Depois disso, todas as camadas ser√£o em Delta

# Delta Lake House
![workflows](extra/workflows.PNG)
____
## ü•â Bronze

**Camada inicial, dados _as is_**


Muito importante que dados nessa camada reflitam o banco ou fonte dos dados

aqui podemos ter duplicidade em vers√µes de dados que devem ser tratados nas camadas posteriores.
Costumo chamar essa camada de "lake"

### Persist√™ncia dos dados

Nessa layer, armazenamos os dados em delta e criamos a delta table no database Bronze.
O arquivo pode ser visto [aqui](https://github.com/gustavocrod/databricks-data-engineering-olist/blob/main/1%20-%20Bronze/bronze_olist.ipynb)

____

## ü•à Silver

**camada de limpeza, normaliza√ß√£o e enriquecimento de dados.**

e.g., 
 - uppercase
 - data textual para tipo date
 - dias em atraso (diferen√ßa entre data atual e data de envimento)

p.s. embora tenha visto v√°rias implementa√ß√µes distintas em projetos que atuei, prefiro desconsiderar as regras de neg√≥cio nessa camada (deixamos para aplicar na camada gold)

### Transforma√ß√µes

Nessa layer aplicamos "enriquecimento" de dados. Fizemos isso agregando e manipulando campos como "data de entrega" e "data do envio" para calculado o "tempo de entrega".

Esses dados s√£o utilizados para analytics. Os arquivos dessa camada podem ser vistos [aqui](https://github.com/gustavocrod/databricks-data-engineering-olist/tree/main/2%20-%20Silver)

----
## ü•á Gold

**camada para aplica√ß√£o de regras de neg√≥cio**

e.g.,
 - jun√ß√£o/uni√£o de tabelas
 - filtro de dados

 Nessa camada aplicamos dois tipos de agrega√ß√µes:
  * **1 - agrega√ß√£o _estilo_ dimens√£o e fato.** _i.e._, adicionamos joins entre as tabelas, conforme o schema disponibilizado.
  Dessa forma v√°rias agrega√ß√µes podem ser feitas ao conectar essa tabela diretamente em ferramentes de visualiza√ß√£o como o Power BI e Metabase. Sendo ela como uma esp√©cie de data mart
  * **2 - agrega√ß√£o anal√≠tica**. _i.e._, sumariza√ß√£o de dados.
  Dessa forma podemos adicionar em ferramentas mais simples ou tamb√©m √© util para algum analista que n√£o det√©m conhecimento em SQL.
Os arquivos dessa camada podem ser vistos [aqui](https://github.com/gustavocrod/databricks-data-engineering-olist/tree/main/3%20-%20Gold)

___

### üìú Caso de estudo RFV

  Para responder as quest√µes levantadas, tivemos um trabalho extra para explicitar a quest√£o **5 Quais s√£o os maiores compradores?**. Aqui avan√ßamos para montar a base par an√°lise de padr√£o de compras por clientes: **RFV**


RFV, ou Recency, Frequency, and Value, √© uma t√©cnica de an√°lise de dados frequentemente usada em marketing e gerenciamento de clientes para segmentar clientes com base em seu comportamento de compra.

Essa abordagem analisa tr√™s aspectos principais do comportamento do cliente:

- **Recency (Rec√™ncia):** Refere-se √† √∫ltima vez que um cliente fez uma compra. Geralmente, clientes que fizeram compras recentes s√£o mais propensos a fazer compras futuras do que aqueles que n√£o compraram h√° muito tempo.
- **Frequency (Frequ√™ncia):** Refere-se √† frequ√™ncia com que um cliente faz compras durante um determinado per√≠odo de tempo. Clientes que compram com frequ√™ncia podem ser considerados mais leais e valiosos para a empresa.
- **Value (Valor):** Refere-se ao valor monet√°rio total das compras feitas por um cliente durante um determinado per√≠odo de tempo. Clientes que gastam mais t√™m um valor de vida do cliente mais alto e podem ser alvos de estrat√©gias de marketing mais agressivas.

Ao analisar esses tr√™s aspectos juntos, as empresas podem segmentar seus clientes em diferentes grupos com base em seu comportamento de compra e adaptar suas estrat√©gias de marketing e relacionamento com o cliente de acordo. Por exemplo, clientes com alta rec√™ncia, frequ√™ncia e valor podem ser segmentados como clientes VIP e receber ofertas exclusivas, enquanto clientes com baixa rec√™ncia, frequ√™ncia e valor podem ser alvos de campanhas de reativa√ß√£o.

## Dashboard
![dash final](extra/dash.PNG)

Ao analisar o dashboard, podemos ver que em SP √© onde tem o maior numero de compradores (faz sentido pela popula√ß√£o).
Podemos ver tamb√©m as TOP5 cidades que mais venderam e os TOP5 clientes de mais compraram

Podemos observar tamb√©m a rela√ß√£o entre o tempo de despache e o tempo total da compra at√© recebimento da mercadoria. Embora tenha liga√ß√£o linear, podemos observar que v√°rios casos tem atraso mesmo quando o despache √© agil.

Por fim, observamos que compras feitas no final de semana possuem maior m√©dia de dias em atraso para a entrega.
