# üóÉÔ∏è Brazilian ecommerce olist

Ap√≥s ingerirmos os dados do Kaggle, iremos fazer transforma√ß√µes e responder algumas perguntas de neg√≥cio, como:
- 1: Quantas vendas ocorrem por estado?
- 2: Qual loja/cidade captou o maior valor em vendas?
  - 2.1: Quanto desse valor veio por valor do produto?
  - 2.2: Quando desse valor foi por frete?
- 3: Qual a rela√ß√£o entre o dia de compra e o atraso na entrega?
- 4: Qual a rela√ß√£o entre o tempo da compra at√© o envio com o tempo total at√© a entrega?
- 5: Quais s√£o os maiores compradores? (rec√™ncia, frequ√™ncia e valor gasto)

Essas e outras tantas perguntas podem ser respondidas com os dados que trataremos.

Juntem-se a mim, enquanto temos um overview do projeto.


Este √© um conjunto de dados p√∫blicos de com√©rcio eletr√¥nico brasileiro das compras feitas na loja Olist. O conjunto de dados cont√©m informa√ß√µes de 100 mil pedidos de 2016 a 2018 feitos em v√°rios marketplaces no Brasil. Suas caracter√≠sticas permitem visualizar um pedido em v√°rias dimens√µes: desde o status do pedido, pre√ßo, pagamento e desempenho de frete at√© a localiza√ß√£o do cliente, atributos do produto e, finalmente, avalia√ß√µes escritas pelos clientes. Tamb√©m disponibilizamos um conjunto de dados de geolocaliza√ß√£o que relaciona os c√≥digos postais brasileiros √†s coordenadas lat/long.

Estes s√£o dados comerciais reais, foram anonimizados, e as refer√™ncias √†s empresas e parceiros no texto de revis√£o foram substitu√≠das pelos nomes das grandes casas de Game of Thrones.

## 0 - beginning

Antes de tudo, executamos um script para cria√ß√£o dos databases (bronze, silver e gold)

## 1 - Ingest√£o de dados (staging)
O arquivo .ipynb respons√°vel pela ingest√£o pode ser visto [aqui](https://github.com/gustavocrod/databricks-data-engineering-olist/blob/main/0%20-%20data_ingestion%20(staging).ipynb)

O dataset escolhido foi o [Brazilian E-Commerce Public Dataset by Olist](https://www.kaggle.com/datasets/olistbr/brazilian-ecommerces)
Utilizamos do opendatasets para fazer download diretamente do kaggle, ao adicionar as credenciais em um arquivo chamado kaggle.json na raiz do projeto (arquivo ignorado pelo .gitignore).


Como √© um dataset est√°tico (ou quase 100%), n√£o faz sentido adicionar upsert e tampouco streaming.

Mas aqui poder√≠amos utilizar do AutoLoader, ou at√© mesmo de alguma ferramenta com CDC, como airbyte.

Nossa staging n√£o precisaria existir (apenas caso fossem dados vindos por airbyte, por exemplo). Mas criamos para exemplificar, pois irei salvar a staging em parquet. Depois disso, todas as camadas ser√£o em Delta.

# Delta Lake House
Workflow
![workflows](extra/workflows.PNG)

Agendamento
![agendamento](extra/agendamento.PNG)
____
## ü•â Bronze

**Camada inicial, dados _as is_**

Muito importante que dados nessa camada reflitam o banco ou fonte dos dados

aqui podemos ter duplicidade em vers√µes de dados que devem ser tratados nas camadas posteriores.
Costumo chamar essa camada de "lake"
### 1 - Processamento da camada bronze

O arquivo pode ser visto [aqui](https://github.com/gustavocrod/databricks-data-engineering-olist/blob/main/1%20-%20Bronze/bronze_olist.ipynb)

Aqui vamos adicionar uma estrutura que permite um la√ßo de repeti√ß√£o.
O la√ßo ser√° respons√°vel por armazenar os dados e criar tabela delta para cada "entidade" definida no diagrama ER


### 2 - Persist√™ncia

Estamos pegando os arquivos em parquet (passo apenas did√°tico), salvando os dados em delta e criando as tabelas delta

____

## ü•à Silver

**camada de limpeza, normaliza√ß√£o e enriquecimento de dados.**

e.g., 
 - uppercase
 - data textual para tipo date
 - dias em atraso (diferen√ßa entre data atual e data de envimento)

p.s. embora tenha visto v√°rias implementa√ß√µes distintas em projetos que atuei, prefiro desconsiderar as regras de neg√≥cio nessa camada (deixamos para aplicar na camada gold)
Na camada silver, limpezas e ajustes em dados devem ser aplicados
Caso seja poss√≠vel, enriquecer os dados e extrair dados tamb√©m deve acontecer nessa camada (defini√ß√£o adotada)

### Data cleaning

Aqui, a grande maioria das tabelas n√£o foi alterada em rela√ß√£o a bronze.

#### 1 - silver_geolocation
Somente iremos realizar um ajuste no outlier seller_city "04482255"

``df = df.filter("seller_city != '04482255'")``

### Transforma√ß√µes

Nessa layer aplicamos "enriquecimento" de dados. Fizemos isso agregando e manipulando campos como "data de entrega" e "data do envio" para calculado o "tempo de entrega".

#### [1 - silver_customers](https://github.com/gustavocrod/databricks-data-engineering/blob/main/project_ecommerce_olist/2%20-%20Silver/silver_customers.ipynb)
#### [2 - silver_geolocation](https://github.com/gustavocrod/databricks-data-engineering/blob/main/project_ecommerce_olist/2%20-%20Silver/silver_geolocation.ipynb)
#### [3 - silver_order_items](https://github.com/gustavocrod/databricks-data-engineering/blob/main/project_ecommerce_olist/2%20-%20Silver/silver_order_items.ipynb)
#### [4 - silver_order_payments](https://github.com/gustavocrod/databricks-data-engineering/blob/main/project_ecommerce_olist/2%20-%20Silver/silver_order_payments.ipynb)
#### [5 - silver_order_reviews](https://github.com/gustavocrod/databricks-data-engineering/blob/main/project_ecommerce_olist/2%20-%20Silver/silver_order_reviews.ipynb)
#### [6 - silver_orders](https://github.com/gustavocrod/databricks-data-engineering/blob/main/project_ecommerce_olist/2%20-%20Silver/silver_orders.ipynb)

Inicialmente iremos carregar dados para agrega√ß√µes:
 - Campo mes/ano para calcular vendas mensais, trimestrais e etc

Podemos nos focar no tempo decorrido de cada etapa, por exemplo:
 - tempo at√© a aprova√ß√£o (em minutos ou segundos)
 - tempo de entrega (em dias)
 - tempo total da compra at√© a entrega (em dias)
 - atraso (divergencia entre tempo estimado e o entregue)

 Al√©m disso, podemos trazer dados que auxiliem na analise do padr√£o de compra por data
  - dia da semana
  - √© fim de semana?

aqui poderia estressar e ir at√© para coisas do tipo:
pandas_market_calendars
 - √© feriado?
 - qual feriado
 - dias at√© o pr√≥ximo feriado - para entender padr√µes de compra pr√≥ximo a feriados

#### [7 - silver_products](https://github.com/gustavocrod/databricks-data-engineering/blob/main/project_ecommerce_olist/2%20-%20Silver/silver_products.ipynb)
#### [8 - silver_sellers](https://github.com/gustavocrod/databricks-data-engineering/blob/main/project_ecommerce_olist/2%20-%20Silver/silver_sellers.ipynb)

----
## ü•á Gold

**camada para aplica√ß√£o de regras de neg√≥cio**

e.g.,
 - jun√ß√£o/uni√£o de tabelas
 - filtro de dados

 Nessa camada aplicamos dois tipos de agrega√ß√µes:
  * **1 - agrega√ß√£o _estilo_ dimens√£o e fato.** _i.e._, adicionamos joins entre as tabelas, conforme o schema disponibilizado.
  Dessa forma v√°rias agrega√ß√µes podem ser feitas ao conectar essa tabela diretamente em ferramentes de visualiza√ß√£o como o Power BI e Metabase. Sendo ela como uma esp√©cie de data mart
  * **2 - agrega√ß√£o anal√≠tica**. _i.e._, sumariza√ß√£o de dados.
  Dessa forma podemos adicionar em ferramentas mais simples ou tamb√©m √© util para algum analista que n√£o det√©m conhecimento em SQL.
Os arquivos dessa camada podem ser vistos [aqui](https://github.com/gustavocrod/databricks-data-engineering-olist/tree/main/3%20-%20Gold)

### [1 - gold_orders](https://github.com/gustavocrod/databricks-data-engineering/blob/main/project_ecommerce_olist/3%20-%20Gold/gold_orders.ipynb)
Conforme o schema disponibilizado, iremos agregar os dados em uma big table que permitir√° ~quase~ todas as analises subsequentes

Apenas para fins de teste, iremos agregar apenas reviews e payments √† table "fact" orders;
Portanto, iremos carregar essas tabelas

### [2 - gold_customer_orders](https://dbc-95ac872f-197a.cloud.databricks.com/?o=3400972147665339#notebook/4240245637785921/command/4240245637786376)
Essa √© uma tabela de sumariza√ß√£o.

O objetivo dela √© responder sobre as compras dos clientes.

Conseguir√≠amos responder quest√µes como:
 - Quantas vendas ocorreram por estado
 - poderiamos ver as vendas por mes e ano
 - poderiamos ver dados sobre valores das vendas
 - dados sobre as entregas, como a rela√ß√£o do dia da compra e atraso na entrega

### [3 - gold_multiple_order](https://github.com/gustavocrod/databricks-data-engineering/blob/main/project_ecommerce_olist/3%20-%20Gold/gold_multiple_orders.ipynb)
Essa √© uma tabela sumarizada anal√≠tica.

O objetivo dela √© informar os meses em que tiveram mais pedidos;
 - multiple_orders: informar se o cliente comprou mais de uma vez

### [4 - gold_total_orders_by_month_year](https://github.com/gustavocrod/databricks-data-engineering/blob/main/project_ecommerce_olist/3%20-%20Gold/gold_total_orders_month_year.ipynb)
Essa √© uma tabela sumarizada anal√≠tica.
Nessa tabela, agrupamos por mes/ano e contamos o total de orders

### [5 - gold_total_orders_profit_by_seller_city](https://github.com/gustavocrod/databricks-data-engineering/blob/main/project_ecommerce_olist/3%20-%20Gold/gold_total_orders_profit_by_seller_city.ipynb)
Essa √© uma tabela sumarizada anal√≠tica.
O objetivo dela √© informar o total de venda bruta por cada vendedor (aqui temos cidade vendedora)
___

### üìú Caso de estudo RFV

  Para responder as quest√µes levantadas, tivemos um trabalho extra para explicitar a quest√£o **5 Quais s√£o os maiores compradores?**. Aqui avan√ßamos para montar a base par an√°lise de padr√£o de compras por clientes: **RFV**


RFV, ou Recency, Frequency, and Value, √© uma t√©cnica de an√°lise de dados frequentemente usada em marketing e gerenciamento de clientes para segmentar clientes com base em seu comportamento de compra.

Essa abordagem analisa tr√™s aspectos principais do comportamento do cliente:

- **Recency (Rec√™ncia):** Refere-se √† √∫ltima vez que um cliente fez uma compra. Geralmente, clientes que fizeram compras recentes s√£o mais propensos a fazer compras futuras do que aqueles que n√£o compraram h√° muito tempo.
- **Frequency (Frequ√™ncia):** Refere-se √† frequ√™ncia com que um cliente faz compras durante um determinado per√≠odo de tempo. Clientes que compram com frequ√™ncia podem ser considerados mais leais e valiosos para a empresa.
- **Value (Valor):** Refere-se ao valor monet√°rio total das compras feitas por um cliente durante um determinado per√≠odo de tempo. Clientes que gastam mais t√™m um valor de vida do cliente mais alto e podem ser alvos de estrat√©gias de marketing mais agressivas.

Ao analisar esses tr√™s aspectos juntos, as empresas podem segmentar seus clientes em diferentes grupos com base em seu comportamento de compra e adaptar suas estrat√©gias de marketing e relacionamento com o cliente de acordo. Por exemplo, clientes com alta rec√™ncia, frequ√™ncia e valor podem ser segmentados como clientes VIP e receber ofertas exclusivas, enquanto clientes com baixa rec√™ncia, frequ√™ncia e valor podem ser alvos de campanhas de reativa√ß√£o.

## Dashboard
![dash final](extra/dash.PNG)

Ao analisar o dashboard, podemos ver que em SP √© onde tem o maior numero de compradores (faz sentido pela popula√ß√£o).
Podemos ver tamb√©m as TOP5 cidades que mais venderam e os TOP5 clientes de mais compraram

Podemos observar tamb√©m a rela√ß√£o entre o tempo de despache e o tempo total da compra at√© recebimento da mercadoria. Embora tenha liga√ß√£o linear, podemos observar que v√°rios casos tem atraso mesmo quando o despache √© agil.

Por fim, observamos que compras feitas no final de semana possuem maior m√©dia de dias em atraso para a entrega.
