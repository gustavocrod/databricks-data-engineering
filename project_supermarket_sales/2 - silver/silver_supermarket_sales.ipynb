{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "24088d38-e56c-470c-8597-ee8e756ff1c3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ../../_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "66496b9b-610f-4059-bbc6-0343ec6039ae",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import hour, minute, second, concat, lit, date_format, dayofweek, when, month, year\n",
    "from pyspark.sql.types import StringType"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b16de0de-365e-4394-94c7-c52a88f5eb5c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "# Camada Silver\n",
    "\n",
    "Na camada silver, limpezas e ajustes em dados devem ser aplicados\n",
    "\n",
    "Caso seja possível, enriquecer os dados e extrair dados também deve acontecer nessa camada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "720864c5-5f92-4f97-86a4-d702ead96b63",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "tb_name = \"silver.supermarket_sales\"\n",
    "target_location = \"dbfs:/delta/silver/supermarket_sales\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4de19ac2-b05a-45e2-9760-61eecc128e9a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## 1 - Data ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1418c6ea-6e08-4bfc-bf2e-1e37b716e49c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = spark.read.table(\"bronze.supermarket_sales\") # leituira da delta table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ee2bec15-ea71-4efa-832b-64bb70450e8a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5250c8b5-39f9-43c4-a427-6d0e5706f6ca",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(df.take(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9f152a10-12a2-47db-aa11-7fdb4499f64b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "## 2 - Data Munging\n",
    "\n",
    "Processo de limpeza e normalizações necessárias\n",
    "\n",
    "Como esses dados já são bem tratados, vamos apenas corrigir o campo \"time\" para conter a data e verificar a possibilidade de criação de algum outro campo (como campo timestamp ao unir date e time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ba12075d-494b-43f9-9947-aaf8e2864c1f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "### timestamp da venda\n",
    "\n",
    "Juntar a data/hora do campo \"time\" e unir com o campo \"date\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "59f4d466-e9e3-40ad-abef-d80bb61a1aec",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Extrair a hora, minutos e segundos\n",
    "df = df.withColumns({\"hora\": hour(col(\"time\")), \n",
    "                     \"minuto\": minute(col(\"time\")),\n",
    "                     \"segundo\": second(col(\"time\"))}) # withColumns eu nao costumo usar, mas vi no linkedin e vim testar rs\n",
    "\n",
    "# concatenação da data com a hora, minutos e segundos, além dos literais T, : e Z para formar string de timestamp\n",
    "df = df.withColumn(\"sale_time\", \n",
    "                   concat(\n",
    "                       col(\"date\").cast(StringType()), lit(\"T\"),\n",
    "                       col(\"hora\").cast(StringType()), lit(\":\"),\n",
    "                       col(\"minuto\").cast(StringType()), lit(\":\"),\n",
    "                       col(\"segundo\").cast(StringType()), lit(\"Z\")\n",
    "                   ).cast(\"timestamp\")) # cast para timestamp\n",
    "\n",
    "# drop de campos intermediarios\n",
    "df = df.drop(\"time\",\"hora\", \"minuto\", \"segundo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "635d498e-3761-4311-afd2-a3f2b0ecb039",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "### mes/ano da venda\n",
    "\n",
    "Campo desse tipo ajuda para calcular vendas mensais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e3f9fff4-fa22-465e-a5be-340aaf73a721",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = df.withColumns(\n",
    "    {\n",
    "        \"month_year\": date_format(\"date\", \"MM-yyy\"),\n",
    "        \"sale_month\": month(\"date\"),\n",
    "        \"sale_year\": year(\"date\"),\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9312b86f-231e-461c-9a21-6d76bbbaea47",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "### taxa por unidade\n",
    "\n",
    "um campo apenas para manipulação de dados,\n",
    "mas será apenas o total de taxa (5%) divididos pela quantidade vendida. tendo assim a taxa unitaria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b7ff6159-9029-49dc-bd0a-a056db6ff19a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = df.withColumn(\"total_tax_unity\", col(\"tax_5\")/col(\"quantity\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ed7de05a-8871-4f76-acb5-5395d2c17e12",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Dia da semana (numero e descrição)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c02b3abd-8b03-4c98-b088-11f71892d730",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = df.withColumn(\"number_day_of_week\", dayofweek(col(\"date\")))\n",
    "\n",
    "# Traduzir os números do dia da semana para o português\n",
    "df = df.withColumn(\n",
    "    \"day_of_week\",\n",
    "    when(df[\"number_day_of_week\"] == 1, \"Domingo\")\n",
    "    .when(df[\"number_day_of_week\"] == 2, \"Segunda-feira\")\n",
    "    .when(df[\"number_day_of_week\"] == 3, \"Terça-feira\")\n",
    "    .when(df[\"number_day_of_week\"] == 4, \"Quarta-feira\")\n",
    "    .when(df[\"number_day_of_week\"] == 5, \"Quinta-feira\")\n",
    "    .when(df[\"number_day_of_week\"] == 6, \"Sexta-feira\")\n",
    "    .when(df[\"number_day_of_week\"] == 7, \"Sábado\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "39c6c41d-2d0a-42cf-912d-f1cb6f9b2531",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "### weekend?\n",
    "\n",
    "criar um campo para informar se a data é um fim de semana (não faz muito sentido, mas vamos supor que foi uma regra de negócio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d6ae1b6b-7359-4c3d-82cd-32c9cbf21e01",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = df.withColumn(\n",
    "    \"weekend\",\n",
    "    when(col(\"day_of_week\").isin([\"Sábado\", \"Domingo\"]), True).otherwise(False),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e83c8774-b0d8-4d2d-8d50-5438a1aa4280",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(df.take(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d101dbed-c734-4506-8155-971ad97bf563",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "belezura!\n",
    "\n",
    "Limpamos um cadim, enriquecemos e transformamos algumas coisas e temos nosso dataset preparado para analises (até preditiva e prescritiva -> mas aí tem que fazer um pouco mais de cleanings e etc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "02ee1fa1-b1dd-4c6f-a1ce-576ab5766b90",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Saving data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a1430309-2c03-42fe-9961-d395c70efc7b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "tb_name = 'silver.supermarket_sales'\n",
    "target_location = '/FileStore/delta/supermarket_sales/silver'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "65395fd6-b78b-46bc-9f4a-c054d9e4752a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "save_dataframe(df, \"delta\", target_location=target_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "364c0377-b808-40cb-a6c2-2dbe24acb496",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "## create delta table\n",
    "\n",
    "TODO: implementar UPSERT\n",
    "\n",
    "o upsert serve para não precisar reescrever todos os dados, mas aproveitar do Delta para fazer um MERGE, caso um registro antigo tenha uma nova versão e INSERT para os dados que são novos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aba5f321-eb15-47cf-ae6c-67b8d939313e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "create_table(tb_name, target_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "06773b95-c6de-43f7-afe3-0c48342bdc05",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# exit para fechar a execução\n",
    "dbutils.notebook.exit(\"OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a2349d0b-2584-4629-be54-142b53a5ee54",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "select\n",
    "  *\n",
    "from\n",
    "  silver.supermarket_sales\n",
    "limit\n",
    "  10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "61ff1870-fa6f-478d-a799-bbeea6490638",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 4240245637786628,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "silver_supermarket_sales",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
